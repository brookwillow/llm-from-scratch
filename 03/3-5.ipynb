{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0e74f3eb",
   "metadata": {},
   "source": [
    "# 因果注意力的掩码实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "51bacff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7a75d0aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "context_length = 6\n",
    "ones = torch.ones(context_length, context_length)\n",
    "print(ones)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0edd443b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Causal mask:\n",
      " tensor([[0., 1., 1., 1., 1., 1.],\n",
      "        [0., 0., 1., 1., 1., 1.],\n",
      "        [0., 0., 0., 1., 1., 1.],\n",
      "        [0., 0., 0., 0., 1., 1.],\n",
      "        [0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "mask = torch.triu(ones, diagonal=1)\n",
    "print(\"Causal mask:\\n\", mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "34afca30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention scores before masking:\n",
      " tensor([[0.9255, 0.0453, 0.5155, 0.9033, 0.1484, 0.8146],\n",
      "        [0.6408, 0.8407, 0.0115, 0.4654, 0.0346, 0.0527],\n",
      "        [0.7147, 0.1970, 0.1273, 0.3279, 0.1407, 0.6383],\n",
      "        [0.2883, 0.7989, 0.6767, 0.3149, 0.8252, 0.4870],\n",
      "        [0.5743, 0.1173, 0.0506, 0.7206, 0.8865, 0.5583],\n",
      "        [0.4314, 0.9827, 0.0439, 0.4720, 0.5172, 0.4862]])\n"
     ]
    }
   ],
   "source": [
    "attn_scores = torch.rand(6, 6)\n",
    "print(\"Attention scores before masking:\\n\", attn_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "65be9184",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention scores after applying causal mask:\n",
      " tensor([[0.9255,   -inf,   -inf,   -inf,   -inf,   -inf],\n",
      "        [0.6408, 0.8407,   -inf,   -inf,   -inf,   -inf],\n",
      "        [0.7147, 0.1970, 0.1273,   -inf,   -inf,   -inf],\n",
      "        [0.2883, 0.7989, 0.6767, 0.3149,   -inf,   -inf],\n",
      "        [0.5743, 0.1173, 0.0506, 0.7206, 0.8865,   -inf],\n",
      "        [0.4314, 0.9827, 0.0439, 0.4720, 0.5172, 0.4862]])\n"
     ]
    }
   ],
   "source": [
    "masked_scores = attn_scores.masked_fill(mask.bool(), -torch.inf)\n",
    "print(\"Attention scores after applying causal mask:\\n\", masked_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "636486ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention weights after applying causal mask:\n",
      " tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.4502, 0.5498, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.4648, 0.2769, 0.2583, 0.0000, 0.0000, 0.0000],\n",
      "        [0.1935, 0.3224, 0.2853, 0.1987, 0.0000, 0.0000],\n",
      "        [0.2105, 0.1333, 0.1247, 0.2437, 0.2877, 0.0000],\n",
      "        [0.1515, 0.2629, 0.1028, 0.1578, 0.1650, 0.1600]])\n"
     ]
    }
   ],
   "source": [
    "attn_weights = torch.softmax(masked_scores, dim=-1)\n",
    "print(\"Attention weights after applying causal mask:\\n\", attn_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06a0289b",
   "metadata": {},
   "source": [
    "# 使用dropout 掩码额外的注意力权重"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a91eabd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2., 2., 0., 2., 2., 0.],\n",
      "        [0., 0., 0., 2., 0., 2.],\n",
      "        [2., 2., 2., 2., 0., 2.],\n",
      "        [0., 2., 2., 0., 0., 2.],\n",
      "        [0., 2., 0., 2., 0., 2.],\n",
      "        [0., 2., 2., 2., 2., 0.]])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "dropout = torch.nn.Dropout(p=0.5)\n",
    "example = torch.ones(6, 6)\n",
    "print(dropout(example))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "533267f1",
   "metadata": {},
   "source": [
    "经过dropout的结果是 50%的数变成0 ，剩余50%变成了原来的一倍"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "46ec6668",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.9295, 0.5539, 0.5166, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.6448, 0.5707, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.2666, 0.0000, 0.4874, 0.0000, 0.0000],\n",
      "        [0.0000, 0.5258, 0.2056, 0.3155, 0.3301, 0.0000]])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "print(dropout(attn_weights))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb51c614",
   "metadata": {},
   "source": [
    "# 实现一个简单的因果注意力类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e0ebac7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 6, 3])\n"
     ]
    }
   ],
   "source": [
    "inputs = torch.tensor(\n",
    "  [[0.43, 0.15, 0.89], # Your     (x^1)\n",
    "   [0.55, 0.87, 0.66], # journey  (x^2)\n",
    "   [0.57, 0.85, 0.64], # starts   (x^3)\n",
    "   [0.22, 0.58, 0.33], # with     (x^4)\n",
    "   [0.77, 0.25, 0.10], # one      (x^5)\n",
    "   [0.05, 0.80, 0.55]] # step     (x^6)\n",
    ")\n",
    "batch = torch.stack((inputs, inputs), dim=0)  # (B=2, T=6, C=3)\n",
    "print(batch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a68a2e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CausalSelfAttention(nn.Module):\n",
    "    def __init__(self, d_in, d_out, context_length, dropout, qkv_bias=False):\n",
    "        super().__init__()\n",
    "\n",
    "        # 按照d_in, d_out初始化Q,K,V的线性变换矩阵\n",
    "        self.W_q = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_k = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_v = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "\n",
    "        # 初始化掩码矩阵\n",
    "        self.register_buffer(\"mask\", torch.triu(torch.ones(context_length, context_length), diagonal=1))\n",
    "\n",
    "        # 初始化dropout层\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "        # 初始化softmax层\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "\n",
    "    def forward(self, X):\n",
    "        \n",
    "        queries = self.W_q(X)  # (B, T, d_out)\n",
    "        keys = self.W_k(X)     # (B, T, d_out)\n",
    "        values = self.W_v(X)   # (B, T, d_out)\n",
    "\n",
    "        attn_scores = queries @ keys.transpose(1,2)\n",
    "        # 掩码矩阵取一下前T行前T列，为了适应不同长度的输入序列\n",
    "        attn_scores = attn_scores.masked_fill(self.mask.bool()[:X.shape[1], :X.shape[1]], -torch.inf)\n",
    "        attn_weights = self.softmax(attn_scores/ keys.shape[-1]**0.5)\n",
    "        masked_attn_weights = self.dropout(attn_weights)\n",
    "\n",
    "        context_vec = masked_attn_weights @ values\n",
    "        return context_vec\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b77f8419",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context vectors shape: torch.Size([2, 6, 2])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "context_length = batch.shape[1]\n",
    "ca = CausalSelfAttention(d_in=3, d_out=2, context_length=context_length, dropout=0.0)\n",
    "context_vec = ca(batch)\n",
    "print(\"Context vectors shape:\", context_vec.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e22d9f7",
   "metadata": {},
   "source": [
    "# 多头注意力"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3c2be45f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 通过一个Wrapper 来实现一个多头注意力的封装类\n",
    "class MultiHeadAttentionWrapper(nn.Module):\n",
    "    def __init__(self, d_in, d_out, context_length, num_heads, dropout, qkbv_bias=False):\n",
    "        super().__init__()\n",
    "        self.heads = nn.ModuleList([\n",
    "            CausalSelfAttention(d_in, d_out, context_length, dropout, qkbv_bias)\n",
    "            for _ in range(num_heads)\n",
    "        ])\n",
    "\n",
    "    def forward(self, X):\n",
    "        head__outpus = [head(X) for head in self.heads]\n",
    "        # 在最后一个维度上进行拼接\n",
    "        return torch.cat(head__outpus, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "99ec9b7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context vectors shape: torch.Size([2, 6, 4])\n",
      "tensor([[[-0.4519,  0.2216,  0.4772,  0.1063],\n",
      "         [-0.5874,  0.0058,  0.5891,  0.3257],\n",
      "         [-0.6300, -0.0632,  0.6202,  0.3860],\n",
      "         [-0.5675, -0.0843,  0.5478,  0.3589],\n",
      "         [-0.5526, -0.0981,  0.5321,  0.3428],\n",
      "         [-0.5299, -0.1081,  0.5077,  0.3493]],\n",
      "\n",
      "        [[-0.4519,  0.2216,  0.4772,  0.1063],\n",
      "         [-0.5874,  0.0058,  0.5891,  0.3257],\n",
      "         [-0.6300, -0.0632,  0.6202,  0.3860],\n",
      "         [-0.5675, -0.0843,  0.5478,  0.3589],\n",
      "         [-0.5526, -0.0981,  0.5321,  0.3428],\n",
      "         [-0.5299, -0.1081,  0.5077,  0.3493]]], grad_fn=<CatBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# 使用我们的多头注意力封装类\n",
    "torch.manual_seed(123)\n",
    "context_length = batch.shape[1]\n",
    "mha = MultiHeadAttentionWrapper(d_in=3, d_out=2, context_length=context_length, num_heads=2, dropout=0.0)\n",
    "context_vec = mha(batch)\n",
    "\n",
    "print(\"Context vectors shape:\", context_vec.shape)\n",
    "print(context_vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68b4780e",
   "metadata": {},
   "source": [
    "# 权重划分实现多头注意力"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6ebbb1ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_in, d_out, context_length, num_heads, dropout, qkv_bias= False):\n",
    "        super().__init__()\n",
    "\n",
    "        self.d_in = d_in\n",
    "        self.d_out = d_out\n",
    "        self.num_heads = num_heads\n",
    "        self.head_dim = d_out // num_heads\n",
    "\n",
    "        # 初始化Q,K,V的线性变换矩阵\n",
    "        self.W_q = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_k = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_v = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "\n",
    "        # 初始化dropout层\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "        # 初始化掩码矩阵\n",
    "        self.register_buffer(\"mask\", torch.triu(torch.ones(context_length, context_length), diagonal=1))\n",
    "\n",
    "        # 初始化softmax层\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "\n",
    "        # 输出的线性变换矩阵\n",
    "        self.W_o = nn.Linear(d_out, d_out)\n",
    "\n",
    "    def forward(self, X):\n",
    "        num_btach, num_tokens, d_in = X.shape\n",
    "\n",
    "        queries = self.W_q(X)  # (num_batch, num_tokens, d_out)\n",
    "        keys = self.W_k(X)     # (num_batch, num_tokens, d_out)\n",
    "        values = self.W_v(X)   # (num_batch, num_tokens, d_out)\n",
    "\n",
    "        # 将d_out维度拆分成(num_heads, head_dim)\n",
    "        queries = queries.view(num_btach, num_tokens, self.num_heads, self.head_dim)\n",
    "        keys = keys.view(num_btach, num_tokens, self.num_heads, self.head_dim)\n",
    "        values = values.view(num_btach, num_tokens, self.num_heads, self.head_dim)\n",
    "\n",
    "        # 钱换一下维度顺序，方便后续计算\n",
    "        keys = keys.transpose(1,2)      # (num_batch, num_heads, num_tokens, head_dim)\n",
    "        queries = queries.transpose(1,2) # (num_batch, num_heads, num_tokens, head_dim)\n",
    "        values = values.transpose(1,2)   # (num_batch, num_heads, num_tokens, head_dim)\n",
    "\n",
    "\n",
    "        # 计算注意力分数,并进行对角线掩码\n",
    "        attn_scores =- queries @ keys.transpose(2,3) # (num_batch, num_heads, num_tokens, num_tokens)\n",
    "        masked_attn_scores = attn_scores.masked_fill(self.mask.bool()[:num_tokens, :num_tokens], -torch.inf)\n",
    "\n",
    "        # 缩放的注意力权重计算\n",
    "        scaled_scores = masked_attn_scores / keys.shape[-1]**0.5\n",
    "        attn_weights = self.softmax(scaled_scores)\n",
    "\n",
    "        # 计算输出上下文向量\n",
    "        context_vec = attn_weights @ values # (num_batch, num_heads, num_tokens, head_dim)\n",
    "        context_vec = context_vec.transpose(1,2)\n",
    "\n",
    "        context_vec = context_vec.contiguous().view(num_btach, num_tokens, self.d_out)\n",
    "\n",
    "        # 最后的线性变换\n",
    "        output = self.W_o(context_vec)\n",
    "        return output\n",
    "\n",
    "\n",
    "          \n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7fccbaf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context vectors shape: torch.Size([2, 6, 2])\n",
      "tensor([[[0.3190, 0.4858],\n",
      "         [0.2926, 0.3957],\n",
      "         [0.2840, 0.3645],\n",
      "         [0.2687, 0.3912],\n",
      "         [0.2618, 0.3974],\n",
      "         [0.2571, 0.4064]],\n",
      "\n",
      "        [[0.3190, 0.4858],\n",
      "         [0.2926, 0.3957],\n",
      "         [0.2840, 0.3645],\n",
      "         [0.2687, 0.3912],\n",
      "         [0.2618, 0.3974],\n",
      "         [0.2571, 0.4064]]], grad_fn=<ViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "batch_size, context_length, d_in = batch.shape \n",
    "d_out = 2\n",
    "mha = MultiHeadAttention(d_in=d_in, d_out=d_out, context_length=context_length, num_heads=2, dropout=0.0)\n",
    "context_vec = mha(batch)\n",
    "print(\"Context vectors shape:\", context_vec.shape)\n",
    "print(context_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f210996b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "local-llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
